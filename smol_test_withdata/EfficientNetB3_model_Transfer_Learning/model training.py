# -*- coding: utf-8 -*-
"""EfficientNetB3_model_for_transfer_learning_and_object_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EXGbMm_GYtIIVV4DxKsPR1FUMQ-3Hewi
"""

! pip install -q kaggle
!pip install h5py

from google.colab import files
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets list

!kaggle datasets download -d sadmansakibmahi/class-of-leaf
#!kaggle datasets download -d emmarex/plantdisease
#!kaggle datasets download -d sadmansakibmahi/plant-disease-expert

!unzip /content/class-of-leaf.zip
#!!unzip /content/plant-disease-expert.zip
#!unzip /content/plantdisease.zip

import numpy as np
import pandas as pd
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import time
import matplotlib.pyplot as plt
import cv2
import seaborn as sns
sns.set_style('darkgrid')
import shutil
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization
from tensorflow.keras.optimizers import Adam, Adamax
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras import regularizers
from tensorflow.keras.models import Model
import time

dataset_path = "/content/Dataset/Dataset"
!pip install efficientnet

"""**Phần 1: Tổng quan về bộ dữ liệu**

Phần này phân tích một bộ dữ liệu bằng cách đếm số lượng hình ảnh trong mỗi lớp. Nó tạo ra một DataFrame với hai cột: "Lớp thực vật" và "Số lượng hình ảnh". Sau đó, dữ liệu được sắp xếp dựa trên số lượng hình ảnh và biểu đồ thanh ngang được vẽ để trực quan hóa sự phân bổ của hình ảnh trên các lớp thực vật khác nhau. 5 lớp hàng đầu có số lượng hình ảnh tối thiểu sẽ được in ra.

**Phần 2: Chuẩn bị bộ dữ liệu**

Phần này chuẩn bị bộ dữ liệu cho máy học. Nó đặt ngưỡng tối thiểu (min_samples) cho số lượng hình ảnh mà một lớp phải có để được đưa vào. Nó tạo ra một DataFrame (df) chứa các đường dẫn tệp và nhãn tương ứng. Sau đó, bộ dữ liệu được chia thành các bộ đào tạo, xác thực và kiểm tra bằng hàm train_test_split. Tập lệnh in độ dài của các bộ này và số lượng lớp trong bộ đào tạo.

**Phần 3: Thống kê bộ dữ liệu**

Phần này tính toán và in số liệu thống kê về bộ dữ liệu đào tạo, chẳng hạn như số lượng hình ảnh trên mỗi lớp. Nó cũng xác định các lớp có số lượng hình ảnh đào tạo tối đa và tối thiểu. Ngoài ra, nó tính toán chiều cao, chiều rộng và tỷ lệ khung hình trung bình của một mẫu hình ảnh từ bộ đào tạo.

Tóm lại, các phần này cùng nhau cung cấp thông tin chi tiết về thành phần của tập dữ liệu, chuẩn bị tập dữ liệu để đào tạo và cung cấp thông tin thống kê hữu ích để hiểu các đặc điểm dữ liệu trước khi xây dựng mô hình học máy.
"""

directory = dataset_path

total_number = 0
total_classes = 0
name_classes = []
len_classes = []

for folder in os.listdir(directory):
    folder_path = os.path.join(directory, folder)
    if os.path.isdir(folder_path):
        num_files = len(os.listdir(folder_path))
        len_classes.append(num_files)
        name_classes.append(folder)
        total_number += num_files
        total_classes += 1

data = {'Plant Class': name_classes, 'Number of Images': len_classes}

df = pd.DataFrame(data)
df_sorted = df.sort_values('Number of Images')

plt.figure(figsize=(20, 15))
plt.barh(df_sorted['Plant Class'], df_sorted['Number of Images'])
plt.title('Overview of the Dataset')
plt.xlabel('Number of Data')
plt.ylabel('Plant Classes')
plt.show()
print("//////////////////////////////")
min_classes = df_sorted.head(5)
print(min_classes[['Plant Class', 'Number of Images']])



print("//////////////////////////////")

sdir=(dataset_path)
min_samples=40 # set limit for minimum images a class must have to be included in the dataframe
filepaths = []
labels=[]
classlist=os.listdir(sdir)
for klass in classlist:
    classpath=os.path.join(sdir, klass)
    flist=os.listdir(classpath)
    if len(flist) >= min_samples:
        for f in flist:
            fpath=os.path.join(classpath,f)
            filepaths.append(fpath)
            labels.append(klass)
    else:
        print('class ', klass, ' has only', len(flist), ' samples and will not be included in dataframe')
Fseries=pd.Series(filepaths, name='filepaths')
Lseries=pd.Series(labels, name='labels')
df=pd.concat([Fseries, Lseries], axis=1)
train_df, dummy_df=train_test_split(df, train_size=.9, shuffle=True, random_state=123, stratify=df['labels'])
valid_df, test_df=train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123, stratify=dummy_df['labels'])
print('train_df lenght: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))
# get the number of classes and the images count for each class in train_df
classes=sorted(list(train_df['labels'].unique()))
class_count = len(classes)
print('The number of classes in the dataset is: ', class_count)
groups=train_df.groupby('labels')
print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))
countlist=[]
classlist=[]
for label in sorted(list(train_df['labels'].unique())):
    group=groups.get_group(label)
    countlist.append(len(group))
    classlist.append(label)
    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))

# get the classes with the minimum and maximum number of train images
max_value=np.max(countlist)
max_index=countlist.index(max_value)
max_class=classlist[max_index]
min_value=np.min(countlist)
min_index=countlist.index(min_value)
min_class=classlist[min_index]
print(max_class, ' has the most images= ',max_value, ' ', min_class, ' has the least images= ', min_value)
# lets get the average height and width of a sample of the train images
ht=0
wt=0
# select 100 random samples of train_df
train_df_sample=train_df.sample(n=100, random_state=123,axis=0)
for i in range (len(train_df_sample)):
    fpath=train_df_sample['filepaths'].iloc[i]
    img=plt.imread(fpath)
    shape=img.shape
    ht += shape[0]
    wt += shape[1]
print('average height= ', ht//100, ' average width= ', wt//100, 'aspect ratio= ', ht/wt)

"""# trim Giải thích về hàm:

Hàm trim được thiết kế để điều chỉnh tập dữ liệu bằng cách giới hạn số lượng mẫu trên mỗi lớp. Sau đây là phân tích từng bước:

**Tham số đầu vào:**

df: DataFrame đầu vào chứa đường dẫn tệp và nhãn.
max_samples: Số lượng mẫu tối đa được phép trên mỗi lớp.
min_samples: Số lượng mẫu tối thiểu cần thiết để một lớp được đưa vào.
column: Cột trong DataFrame biểu thị nhãn lớp.

**Nhóm theo lớp:**

Hàm nhóm DataFrame (df) theo cột (cột) được chỉ định, thường biểu thị nhãn lớp.

**Quy trình cắt:**

Đối với mỗi nhãn (lớp) duy nhất, hàm sẽ kiểm tra số lượng mẫu trong lớp đó.
Nếu số lượng lớn hơn max_samples, hàm sẽ lấy mẫu ngẫu nhiên các trường hợp max_samples từ lớp đó, tạo thành một tập hợp con.
Nếu số lượng nằm giữa min_samples và max_samples (bao gồm), hàm sẽ bao gồm tất cả các mẫu từ lớp đó mà không cắt.
Nếu count nhỏ hơn min_samples, lớp này bị loại khỏi tập dữ liệu đã cắt bớt.

**Kết quả:**

Các tập hợp con đã cắt bớt cho mỗi lớp được nối vào một DataFrame mới (trimmed_df).
Hàm in ra thông báo cho biết số lượng mẫu tối đa và tối thiểu trên mỗi lớp sau khi cắt bớt.

**Đầu ra:**
Hàm trả về DataFrame đã cắt bớt, hiện tuân thủ các giới hạn đã chỉ định về số lượng mẫu trên mỗi lớp.
"""

def trim(df, max_samples, min_samples, column):
    df=df.copy()
    groups=df.groupby(column)
    trimmed_df = pd.DataFrame(columns = df.columns)
    groups=df.groupby(column)
    for label in df[column].unique():
        group=groups.get_group(label)
        count=len(group)
        if count > max_samples:
            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)
            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)
        else:
            if count>=min_samples:
                sampled_group=group
                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)
    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)
    return trimmed_df

max_samples= 198855 # since each class has more than 198855 images all classes will be trimmed to have 50000 images per class
min_samples=36
column='labels'
train_df= trim(train_df, max_samples, min_samples, column)

"""# Giải thích về thiết lập Data Generators:

**Thiết lập tham số:**

batch_size: Số lượng mẫu trên mỗi lô trong quá trình đào tạo.
trgen: Một trình tạo dữ liệu hình ảnh để đào tạo với nhiều phép tăng cường khác nhau như lật ngang, xoay và dịch chuyển.
t_and_v_gen: Một trình tạo dữ liệu hình ảnh để xác thực và thử nghiệm mà không cần thêm phép tăng cường nào.

**Trình tạo dữ liệu đào tạo:**

train_gen: Trình tạo luồng được tạo từ DataFrame đào tạo (train_df).
Hình ảnh được tải từ đường dẫn tệp (x_col='filepaths') với các nhãn tương ứng (y_col='labels').
Kích thước hình ảnh mục tiêu được đặt thành (200, 200) và chế độ màu là RGB.
Trình tạo được đặt để xáo trộn dữ liệu (shuffle=True) và tạo ra các lô có kích thước batch_size.

**Trình tạo dữ liệu xác thực:**

valid_gen: Trình tạo luồng cho dữ liệu xác thực với các tham số tương tự như trình tạo đào tạo, ngoại trừ việc xáo trộn được đặt thành False.

**Dữ liệu thử nghiệm Generator:**

test_gen: Trình tạo luồng cho dữ liệu thử nghiệm.
Tập lệnh tính toán động kích thước lô và các bước thử nghiệm để đảm bảo rằng tất cả các mẫu trong tập thử nghiệm được xử lý chính xác một lần.
Trình tạo được đặt thành không xáo trộn dữ liệu (shuffle=False) để tạo điều kiện cho việc phân tích sau này.

**Trích xuất thông tin:**

Danh sách tên lớp (lớp) và chỉ số tương ứng (class_indices) của chúng được trích xuất từ ​​training generator.

Số lượng lớp được xác định (class_count).
Các nhãn từ training generator thử nghiệm được lưu trữ trong biến nhãn.

**Câu lệnh print:**

Hiển thị thông tin về kích thước lô thử nghiệm, các bước thử nghiệm và số lượng lớp.

In tổng số hình ảnh trong tập đào tạo, xác thực và thử nghiệm.

Tóm lại, tập lệnh này chuẩn bị các trình tạo dữ liệu để tải và tăng cường hiệu quả các hình ảnh trong quá trình đào tạo và đánh giá, đảm bảo khả năng tương thích với kích thước hình ảnh và kích thước lô đã chỉ định.

"""
batch_size=20 # We will use and EfficientetB3 model, with image size of (200, 250) this size should not cause resource error
trgen=ImageDataGenerator(horizontal_flip=True,rotation_range=20, width_shift_range=.2,
                                  height_shift_range=.2, zoom_range=.2 )
t_and_v_gen=ImageDataGenerator()
msg='{0:70s} for train generator'.format(' ')
print(msg, '\r', end='') # prints over on the same line
train_gen=trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=(200, 250),
                                   class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)
msg='{0:70s} for valid generator'.format(' ')
print(msg, '\r', end='') # prints over on the same line
valid_gen=t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size= (200, 250),
                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)
# for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set
# this insures that we go through all the sample in the test set exactly once.
length=len(test_df)
test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]
test_steps=int(length/test_batch_size)
msg='{0:70s} for test generator'.format(' ')
print(msg, '\r', end='') # prints over on the same line
test_gen=t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size= (200, 250),
                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)
# from the generator we can get information we will need later
classes=list(train_gen.class_indices.keys())
class_indices=list(train_gen.class_indices.values())
class_count=len(classes)
labels=test_gen.labels
print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)


print("Total Train Image:-",len(train_df))
print("Total Validation Image:-",len(valid_df))
print("Total Test Image:-",len(test_df))

def show_image_samples(gen ):
    t_dict=gen.class_indices
    classes=list(t_dict.keys())
    images,labels=next(gen) # get a sample batch from the generator
    plt.figure(figsize=(20, 20))
    length=len(labels)
    if length<25:   #show maximum of 25 images
        r=length
    else:
        r=25
    for i in range(r):
        plt.subplot(5, 5, i + 1)
        image=images[i] /255
        plt.imshow(image)
        index=np.argmax(labels[i])
        class_name=classes[index]
        plt.title(class_name, color='black', fontsize=11)
        plt.axis('off')
    plt.show()

show_image_samples(train_gen)
"""# **Mô hình EfficientNetB3 để học chuyển giao**
Hình dạng đầu vào cho hình ảnh được đặt thành (300, 300, 3), biểu diễn chiều cao, chiều rộng và kênh. Sau đó, tập dữ liệu được chia thành các tập huấn luyện và thử nghiệm bằng hàm train_test_split, với phân tầng dựa trên cột 'nhãn' để duy trì phân phối lớp.

EfficientNetB3, một kiến ​​trúc mạng nơ-ron tích chập được huấn luyện trước, được nhập và khởi tạo với các trọng số được tải trước từ ImageNet. Để bảo toàn các trọng số được huấn luyện trước, tất cả các lớp của mô hình cơ sở đều được đóng băng.

Mô hình được xây dựng bằng cách thêm các lớp bổ sung vào cơ sở EfficientNetB3. Nó bao gồm một lớp Gộp trung bình toàn cục, một lớp dày đặc với kích hoạt ReLU, một lớp bỏ qua để ngăn chặn quá trình khớp và một lớp dày đặc cuối cùng với kích hoạt softmax để phân loại nhiều lớp.

Sau đó, mô hình được biên dịch bằng trình tối ưu hóa Adam với tốc độ học được chỉ định, entropy chéo theo danh mục làm hàm mất mát và độ chính xác làm số liệu đánh giá.

Để xử lý dữ liệu hiệu quả, trình tạo dữ liệu (train_gen và test_gen) được tạo bằng ImageDataGenerator từ Keras. Các trình tạo này tạo điều kiện tăng cường dữ liệu theo thời gian thực trong quá trình đào tạo và đảm bảo luồng dữ liệu phù hợp đến mô hình trong quá trình thử nghiệm. Các kỹ thuật tăng cường bao gồm thay đổi tỷ lệ, lật ngang, xoay và dịch chuyển.

Phương pháp flow_from_dataframe được sử dụng để định cấu hình luồng dữ liệu từ Pandas DataFrames (train_df và test_df) đến mô hình. Điều này bao gồm việc chỉ định đường dẫn tệp, nhãn, kích thước mục tiêu và kích thước lô. Ngoài ra, mã hóa one-hot được áp dụng cho nhãn lớp trong quá trình đào tạo.

Nhìn chung, tập lệnh này cung cấp một phương pháp tiếp cận được tổ chức tốt và mô-đun hóa để xây dựng mô hình phân loại hình ảnh. Nó tận dụng khả năng học chuyển giao của EfficientNetB3 và kết hợp các hoạt động thiết yếu như phân tách dữ liệu, biên dịch mô hình và tăng cường dữ liệu để đào tạo mạnh mẽ.
"""
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from efficientnet.tfkeras import EfficientNetB3  # Import EfficientNetB3

# Assuming df contains the file paths and labels
# Adjust the input shape based on the requirements of EfficientNetB3
input_shape = (300, 300, 3)

# Split the dataset into training and testing sets
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['labels'])

# Create an instance of the EfficientNetB3 model pre-trained on ImageNet data
base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=input_shape)

# Freeze the layers of the pre-trained model
for layer in base_model.layers:
    layer.trainable = False

# Build your model on top of the EfficientNetB3 base
num_classes = len(train_df['labels'].unique())
model = keras.Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Create data generators
batch_size = 32
trgen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2)
tgen = ImageDataGenerator(rescale=1./255)

train_gen = trgen.flow_from_dataframe(dataframe=train_df, directory=None,
                                      x_col='filepaths', y_col='labels',
                                      target_size=(input_shape[0], input_shape[1]),
                                      class_mode='categorical',
                                      batch_size=batch_size)

test_gen = tgen.flow_from_dataframe(dataframe=test_df, directory=None,
                                    x_col='filepaths', y_col='labels',
                                    target_size=(input_shape[0], input_shape[1]),
                                    class_mode='categorical',
                                    batch_size=batch_size,
                                    shuffle=False)

"""# **Train the model**"""

# Train the model
epochs = 6  # Adjust the number of epochs as needed
history = model.fit(train_gen,
                    steps_per_epoch=train_gen.samples // batch_size,
                    epochs=epochs,
                    validation_data=test_gen,
                    validation_steps=test_gen.samples // batch_size)

"""# **Additional Training or model re_Training**"""

# Additional Training
additional_epochs = 10  # Adjust the number of additional epochs as needed
history_additional = model.fit(train_gen,
                               steps_per_epoch=train_gen.samples // batch_size,
                               epochs=additional_epochs,
                               validation_data=test_gen,
                               validation_steps=test_gen.samples // batch_size)

"""# **Evaluate the model on the test set**"""

# Evaluate the model on the test set
test_results = model.evaluate(test_gen, steps=test_gen.samples // batch_size)
print("\nTest Set Evaluation:")
print("Test Loss:", test_results[0])
print("Test Accuracy:", test_results[1])

class_indices
classlist

"""# **Generate predictions**"""

# Generate predictions
predictions = model.predict(test_gen, steps=test_gen.samples // batch_size)
predicted_labels = np.argmax(predictions, axis=1)
true_labels = test_gen.classes

def tr_plot(tr_data, start_epoch):
    #Plot the training and validation data
    tacc=tr_data.history['accuracy']
    tloss=tr_data.history['loss']
    vacc=tr_data.history['val_accuracy']
    vloss=tr_data.history['val_loss']
    Epoch_count=len(tacc)+ start_epoch
    Epochs=[]
    for i in range (start_epoch ,Epoch_count):
        Epochs.append(i+1)
    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss
    val_lowest=vloss[index_loss]
    index_acc=np.argmax(vacc)
    acc_highest=vacc[index_acc]
    plt.style.use('fivethirtyeight')
    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)
    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)
    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))
    axes[0].plot(Epochs,tloss, 'r', label='Training loss')
    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )
    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)
    axes[0].set_title('Training and Validation Loss')
    axes[0].set_xlabel('Epochs')
    axes[0].set_ylabel('Loss')
    axes[0].legend()
    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')
    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')
    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)
    axes[1].set_title('Training and Validation Accuracy')
    axes[1].set_xlabel('Epochs')
    axes[1].set_ylabel('Accuracy')
    axes[1].legend()
    plt.tight_layout
    plt.show()

tr_plot(history,0)

def re_training_plot(tr_data, start_epoch):
    # Plot the training and validation data
    tacc = tr_data.history['accuracy']
    tloss = tr_data.history['loss']
    vacc = tr_data.history['val_accuracy']
    vloss = tr_data.history['val_loss']
    Epoch_count = len(tacc) + start_epoch
    Epochs = [i + 1 for i in range(start_epoch, Epoch_count)]
    index_loss = np.argmin(vloss)  # epoch with the lowest validation loss
    val_lowest = vloss[index_loss]
    index_acc = np.argmax(vacc)
    acc_highest = vacc[index_acc]

    plt.style.use('fivethirtyeight')
    sc_label = 'best epoch= ' + str(index_loss + 1 + start_epoch)
    vc_label = 'best epoch= ' + str(index_acc + 1 + start_epoch)

    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))

    # Plotting Training and Validation Loss
    axes[0].plot(Epochs, tloss, 'r', label='Re_Training loss')
    axes[0].plot(Epochs, vloss, 'g', label='Re_Validation loss')
    axes[0].scatter(index_loss + 1 + start_epoch, val_lowest, s=150, c='blue', label=sc_label)
    axes[0].set_title('Training and Validation Loss')
    axes[0].set_xlabel('Epochs')
    axes[0].set_ylabel('Loss')
    axes[0].legend()

    # Plotting Training and Validation Accuracy
    axes[1].plot(Epochs, tacc, 'r', label='Re_Training Accuracy')
    axes[1].plot(Epochs, vacc, 'g', label='Re_Validation Accuracy')
    axes[1].scatter(index_acc + 1 + start_epoch, acc_highest, s=150, c='blue', label=vc_label)
    axes[1].set_title('Training and Validation Accuracy')
    axes[1].set_xlabel('Epochs')
    axes[1].set_ylabel('Accuracy')
    axes[1].legend()

    plt.tight_layout()
    plt.show()

# Plot the initial training history
re_training_plot(history_additional, 0)

# Plot the additional training history
#re_training_plot(history_additional, len(history.history['accuracy']))

"""# **Save the model**"""

subject='model'
save_id= subject+ '.h5'
model_save_loc = save_id
model.save(model_save_loc)
print ('model was saved as ' , model_save_loc )

from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model
import numpy as np

def load_and_preprocess_image(image_path):
    img = image.load_img(image_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Normalize the pixel values to be between 0 and 1
    return img_array

def classify_image(model, image_path, class_labels):
    img_array = load_and_preprocess_image(image_path)
    predictions = model.predict(img_array)
    predicted_class_index = np.argmax(predictions)
    predicted_class = class_labels[predicted_class_index]
    confidence = predictions[0][predicted_class_index]

    return predicted_class, confidence

if __name__ == "__main__":
    # Load the saved model
    model_path = "/content/model.h5"
    loaded_model = load_model(model_path)

    # Define your class labels
    class_labels =['Pepper__bell___Bacterial_spot',
 'Pepper__bell___healthy',
 'Potato___Early_blight',
 'Potato___Late_blight',
 'Potato___healthy',
 'Tomato_Bacterial_spot',
 'Tomato_Early_blight',
 'Tomato_Late_blight',
 'Tomato_Leaf_Mold',
 'Tomato_Septoria_leaf_spot',
 'Tomato_Spider_mites_Two_spotted_spider_mite',
 'Tomato__Target_Spot',
 'Tomato__Tomato_YellowLeaf__Curl_Virus',
 'Tomato__Tomato_mosaic_virus',
 'Tomato_healthy'] # Replace with your actual class labels

    # Provide the path to the image you want to classify
    image_path = "/content/PlantVillage/Pepper__bell___Bacterial_spot/0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot 8964.JPG"

    # Perform image classification
    predicted_class, confidence = classify_image(loaded_model, image_path, class_labels)

    # Print the results
    print(f"Predicted Class: {predicted_class}")
    print(f"Confidence: {confidence}")

"""# **Model Quantization**"""

Model_path = "/content/model.h5"
import tensorflow as tf
model = tf.keras.models.load_model(Model_path)

"""**Optimize.DEFAULT Quantization**"""

import tensorflow as tf
model = tf.keras.models.load_model(Model_path)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
tf_lite_Optimize_DEFAULT_model = converter.convert()
print("Optimize.DEFAULT Quantization:- ",len(tf_lite_Optimize_DEFAULT_model))

"""**OPTIMIZE_FOR_SIZE Quantization**"""

import tensorflow as tf
model = tf.keras.models.load_model(Model_path)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
converter.target_spec.supported_types = [tf.float16]
OPTIMIZE_FOR_SIZE_model = converter.convert()
print("OPTIMIZE_FOR_SIZE Quantization [tf.float16]:- ",len(OPTIMIZE_FOR_SIZE_model))

"""**OPTIMIZE_FOR_LATENCY Quantization**"""

import tensorflow as tf
model = tf.keras.models.load_model(Model_path)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]
converter.target_spec.supported_types = [tf.float16]
OPTIMIZE_FOR_LATENCY_model = converter.convert()
print("OPTIMIZE_FOR_LATENCY Quantization:- ",len(OPTIMIZE_FOR_LATENCY_model))

with open("OPTIMIZE_FOR_SIZE_model.tflite", "wb") as f:
    f.write(OPTIMIZE_FOR_SIZE_model)

# save the DEFAULT Quantization model in HDF5 format
with open("tf_lite_Optimize_DEFAULT_model.tflite", "wb") as f:
    f.write(tf_lite_Optimize_DEFAULT_model)

# save the OPTIMIZE_FOR_LATENCY_model in HDF5 format
with open("OPTIMIZE_FOR_LATENCY_model.tflite", "wb") as f:
    f.write(OPTIMIZE_FOR_LATENCY_model)

import numpy as np
from PIL import Image
import tensorflow as tf

def load_and_preprocess_image(image_path, target_size=(224, 224)):
    img = Image.open(image_path)
    img = img.resize(target_size)
    img_array = np.array(img, dtype=np.float32) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    return img_array

def classify_image_tflite(interpreter, image_path, class_labels):
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    img_array = load_and_preprocess_image(image_path, target_size=(input_details[0]['shape'][1], input_details[0]['shape'][2]))

    interpreter.set_tensor(input_details[0]['index'], img_array)
    interpreter.invoke()

    predictions = interpreter.get_tensor(output_details[0]['index'])
    predicted_class_index = np.argmax(predictions)
    predicted_class = class_labels[predicted_class_index]
    confidence = predictions[0][predicted_class_index]

    return predicted_class, confidence

if __name__ == "__main__":
    # Load the TFLite model
    model_path_tflite = "/content/OPTIMIZE_FOR_SIZE_model.tflite"
    interpreter = tf.lite.Interpreter(model_path=model_path_tflite)
    interpreter.allocate_tensors()

    # Define your class labels
    class_labels = ['Pepper__bell___Bacterial_spot',
 'Pepper__bell___healthy',
 'Potato___Early_blight',
 'Potato___Late_blight',
 'Potato___healthy',
 'Tomato_Bacterial_spot',
 'Tomato_Early_blight',
 'Tomato_Late_blight',
 'Tomato_Leaf_Mold',
 'Tomato_Septoria_leaf_spot',
 'Tomato_Spider_mites_Two_spotted_spider_mite',
 'Tomato__Target_Spot',
 'Tomato__Tomato_YellowLeaf__Curl_Virus',
 'Tomato__Tomato_mosaic_virus',
 'Tomato_healthy']  # Replace with your actual class labels

    # Provide the path to the image you want to classify
    image_path = "/content/PlantVillage/Pepper__bell___Bacterial_spot/0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot 8964.JPG"

    # Perform image classification using TFLite model
    predicted_class, confidence = classify_image_tflite(interpreter, image_path, class_labels)

    # Print the results
    print(f"Predicted Class: {predicted_class}")
    print(f"Confidence: {str(str(100*(confidence)))}")